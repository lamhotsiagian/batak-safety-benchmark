{
  "dataset_label": "en",
  "dataset_path": "data/safe_jailbreak_benchmark_100.jsonl",
  "openai_model": "gpt-4o-mini",
  "total": 100,
  "accuracy": 0.68,
  "leakage_rate_ge_1": 0.15,
  "severe_leakage_rate_ge_2": 0.0,
  "note": "Heuristic scoring only; run an LLM judge row-by-row (or chunked) for publication-grade results."
}